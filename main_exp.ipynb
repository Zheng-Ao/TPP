{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_r import PatentDataset, Sequence\n",
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_set = PatentDataset()\n",
    "# with open('./data/train_set.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train_set.pkl', 'rb') as f:\n",
    "    full_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(pd.Series([seq.seq_t0 for seq in full_set]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_pd = pd.DataFrame({'full': [len(seq) for seq in full_set], 'T_0': [seq.seq_t0 for seq in full_set], 'n_cite': [seq.marks.sum() for seq in full_set]})\n",
    "seq_len_pd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(pd.Series().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2 * 4 * 3 = 24\n",
    "# hidden_state = torch.arange(24).reshape(2,4,3)\n",
    "# hidden_state.shape\n",
    "# hidden_state\n",
    "# hidden_state[[0,1], [3,0]].shape\n",
    "# hidden_state.unsqueeze(1).expand(-1, 5, -1, -1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 在 full_set 中根据年份取 train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   full     T_0  n_cite  1990\n0    14  1977.0      22     9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full</th>\n      <th>T_0</th>\n      <th>n_cite</th>\n      <th>1990</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>1977.0</td>\n      <td>22</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 1990\n",
    "min_len = 3\n",
    "\n",
    "seq_l = [seq.trunc(T, abs_T=True) for seq in full_set]\n",
    "seq_len_pd[T] = np.array([len(seq) for seq in seq_l])\n",
    "\n",
    "keep_l = [len(seq) >= min_len for seq in seq_l]\n",
    "seq_l = [seq for i, seq in enumerate(seq_l) if keep_l[i]]\n",
    "train_set = PatentDataset(seq_l=seq_l)\n",
    "\n",
    "seq_len_pd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = full_set[np.random.randint(len(full_set))]\n",
    "# seq.get_pred_target(T, n_period=5, abs_T=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.id2idx_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len_pd[seq_len_pd[T] < 5][T].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, collate_fn=PatentDataset.collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用作试验的一个 batch\n",
    "batch = next(iter(train_loader))\n",
    "# print(*[b.shape for b in batch], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型超参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "hid_dim=32 \n",
    "mlp_dim=16\n",
    "\n",
    "feature_dim = full_set[0].seq_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(hid_dim, mlp_dim, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(0.6119, grad_fn=<MeanBackward0>),\n tensor(0.4562, grad_fn=<MeanBackward0>))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(*batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# batch 上试验 mape 的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_target = [full_set[i].get_pred_target(T, n_period=5, abs_T=True) for i in full_set.id2idx_pd[batch[-1]]]\n",
    "batch_pred_inter_t = np.array([seq[0] for seq in batch_target])\n",
    "batch_count_target = np.array([seq[1] for seq in batch_target])\n",
    "\n",
    "batch_count_hist = [train_set[i].marks for i in train_set.id2idx_pd[batch[-1]]]\n",
    "# batch_count_target: (batch_size, n_period, 2)\n",
    "# batch_count_hist: (batch_size, seq_len_hist, 2), notice that the seq_len_hist here is not a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# list = []\n",
    "# list.append([4]*5)\n",
    "# list\n",
    "\n",
    "mape = torch.tensor(size=())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_count_hist = []\n",
    "nonself_count_hist = []\n",
    "\n",
    "for array in batch_count_hist:\n",
    "    _count1 = 0\n",
    "    _count2 = 0\n",
    "    _seq1 = []\n",
    "    _seq2 = []\n",
    "    for event  in array:\n",
    "        _count1 += event[0]\n",
    "        _count2 += event[1]\n",
    "    _seq1.append([_count1]*5)\n",
    "    _seq2.append([_count2]*5)\n",
    "    self_count_hist.append(_seq1)\n",
    "    nonself_count_hist.append(_seq2)\n",
    "\n",
    "# self_count_hist: (batch_size, n_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/m8b95fxj7wx4r592n7br8qs80000gn/T/ipykernel_85889/3184834879.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_count_target = torch.tensor(batch_count_target, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_count_pred = model.pred(batch, batch_pred_inter_t)\n",
    "# batch_count_pred: same shape as batch_count_target\n",
    "batch_count_pred = torch.tensor(batch_count_pred, dtype=torch.float32)\n",
    "batch_count_target = torch.tensor(batch_count_target, dtype=torch.float32)\n",
    "# batch_count_target[:, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "dif = batch_count_target -batch_count_pred\n",
    "diff_self = dif[:, :, 0]\n",
    "diff_nonself = dif[:, :, 1]\n",
    "\n",
    "target_self = batch_count_target[:, :, 0]\n",
    "\n",
    "# pred_self.shape, diff_self.shape\n",
    "# pred_self, diff_self: (batch_size, n_period)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## batch_mape = abs(batch_count_pred - batch_count_target)/(batch_count_target + batch_count_hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3812)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/m8b95fxj7wx4r592n7br8qs80000gn/T/ipykernel_85889/3012724314.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self_count_hist = torch.tensor(self_count_hist, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "self_count_hist = torch.tensor(self_count_hist, dtype=torch.float32)\n",
    "# print(self_count_hist.shape, diff_self.shape)\n",
    "self_count_hist = torch.squeeze(self_count_hist)\n",
    "# print(self_count_hist.shape)\n",
    "\n",
    "# print(self_count_hist, pred_self)\n",
    "\n",
    "batch_mape_self = abs(diff_self)/(self_count_hist + target_self + 0.001)       # 有部分年份总次数为0，导致分母为0\n",
    "batch_mape_self_mean = torch.mean(batch_mape_self)\n",
    "print(batch_mape_self_mean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.4370832, 1.4370832],\n       [3.0253067, 3.0253067],\n       [4.7805653, 4.7805653],\n       [6.7204247, 6.7204247],\n       [8.864304 , 8.864304 ]], dtype=float32)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pred(batch, batch_pred_inter_t)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型训练，每个 epoch 的 mape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:00<00:00, 175.74it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 187.53it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 184.62it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 187.34it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 188.93it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 188.89it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 188.27it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 189.17it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 188.54it/s]\n",
      "100%|██████████| 141/141 [00:00<00:00, 187.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26019937, 0.2627829, 0.26301336, 0.26284942, 0.26185748, 0.26218975, 0.26140717, 0.26108715, 0.26313737, 0.26181853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_mape = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_mape = []\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        loss_self, loss_nonself = model.train_batch(batch)\n",
    "\n",
    "        batch_target = [full_set[i].get_pred_target(T, n_period=5, abs_T=True) for i in full_set.id2idx_pd[batch[-1]]]\n",
    "        batch_pred_inter_t = np.array([seq[0] for seq in batch_target])\n",
    "        batch_count_target = np.array([seq[1] for seq in batch_target])\n",
    "\n",
    "        batch_count_hist = [train_set[i].marks for i in train_set.id2idx_pd[batch[-1]]]\n",
    "\n",
    "        self_count_hist = []\n",
    "        nonself_count_hist = []\n",
    "\n",
    "        for array in batch_count_hist:\n",
    "            _count1 = 0\n",
    "            _count2 = 0\n",
    "            _seq1 = []\n",
    "            _seq2 = []\n",
    "            for event  in array:\n",
    "                _count1 += event[0]\n",
    "                _count2 += event[1]\n",
    "            _seq1.append([_count1]*5)\n",
    "            _seq2.append([_count2]*5)\n",
    "            self_count_hist.append(_seq1)\n",
    "            nonself_count_hist.append(_seq2)\n",
    "\n",
    "        batch_count_pred = model.pred(batch, batch_pred_inter_t)\n",
    "        batch_count_pred = torch.tensor(batch_count_pred, dtype=torch.float32)\n",
    "        batch_count_target = torch.tensor(batch_count_target, dtype=torch.float32)\n",
    "\n",
    "        dif = batch_count_target - batch_count_pred\n",
    "        diff_self = dif[:, :, 0]\n",
    "        diff_nonself = dif[:, :, 1]\n",
    "\n",
    "        target_self = batch_count_target[:, :, 0]\n",
    "        target_nonself = batch_count_target[:, :, 1]\n",
    "        self_count_hist = torch.tensor(self_count_hist, dtype=torch.float32)\n",
    "        self_count_hist = torch.squeeze(self_count_hist)\n",
    "        nonself_count_hist = torch.tensor(nonself_count_hist, dtype=torch.float32)\n",
    "        nonself_count_hist = torch.squeeze(nonself_count_hist)\n",
    "        batch_mape = abs(diff_self + diff_nonself)/(self_count_hist + nonself_count_hist + target_nonself + target_self + 0.001)\n",
    "        batch_mape_mean = torch.mean(batch_mape)\n",
    "        epoch_mape.append(batch_mape_mean)\n",
    "\n",
    "    mape = np.mean(epoch_mape)\n",
    "    total_mape.append(mape)\n",
    "\n",
    "print(total_mape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([51, 12, 1])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][:, :-1, [0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08338442a0ef8a6778d107bc150a61774a801304dd5e29a26405546c6071bc4b"
  },
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}